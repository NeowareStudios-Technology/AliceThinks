# AliceThinks™ by NeoWare
  The AliceThinks™ application is an iOS native build using emerging technologies. These include the Apple Vision and Machine Learning frameworks to identify items. Once done the application will then allow user to tap on the screen to display an AR 3D model of the word specified in the real world space. 

# How It Works

**- Once the application is installed on the device the user simply opens the application.**

<a href="https://imgflip.com/gif/2bnjhf"><img src="https://i.imgflip.com/2bnjhf.gif" title="made at imgflip.com"/></a>

**- In the bottom right corner of the app you will notice something called 'Recognition Process'. Here the camera view along with the Machine Learning model will give you the top results for what it believes it is looking at.**

<a href="https://imgflip.com/gif/2bnjef"><img src="https://i.imgflip.com/2bnjef.gif" title="made at imgflip.com"/></a>

**- When you are focused on an item you may tap on the screen in the location you feel fit and an augmented 3D label will be placed in that location with the word of the top result as seen in the 'Recognition Process'.**

<a href="https://imgflip.com/gif/2bnjgf"><img src="https://i.imgflip.com/2bnjgf.gif" title="made at imgflip.com"/></a>


# Technologies Used

### Apple Vision Framework

```The Vision framework performs face and face landmark detection, text detection, barcode recognition, image registration, and general feature tracking. Vision also allows the use of custom Core ML models for tasks like classification or object detection.```

### Apple Machine Learning Model

```Core ML 2 lets you integrate a broad variety of machine learning model types into your app. In addition to supporting extensive deep learning with over 30 layer types, it also supports standard models such as tree ensembles, SVMs, and generalized linear models. Because it’s built on top of low level technologies like Metal and Accelerate, Core ML seamlessly takes advantage of the CPU and GPU to provide maximum performance and efficiency. You can run machine learning models on the device so data doesn't need to leave the device to be analyzed.```

### Apple AR Kit

```ARKit allows developers to build high-detail AR experiences for iPad and iPhone. Environments captured through the device can have animated 3D virtual text, objects and characters added to them. AR scenes made by one individual are persistent and can be seen by others visiting the location later.```




## Where Can You Find Us?

* [ALICE Webpage](https://leapwithalice.io)
* [NeoWare Webpage](Neoware.io)
* [Alice iOS App](https://itunes.apple.com/us/app/leap-with-alice/id1369587027?platform=iphone&preserveScrollPosition=true&platform=iphone&platform=iphone&platform=iphone#platform/iphone&platform=iphone&platform=iphone&platform=iphone)
* [Alice Android App](https://play.google.com/store/apps/details?id=com.lwa.alicelens)
* [Facebook](https://www.facebook.com/LeapWithAlice/?ref=br_rs)
* [Twitter](https://twitter.com/LeapWithAlice) 
* [Telegram](https://t.me/LWAlice)
* [Youtube](https://www.youtube.com/channel/UCrrw59HelHtZcLsNwUMCsIA?view_as=subscriber) 
* [Github](https://github.com/AlfonsoMorales/Leap-With-Alice-Demo)
* [Medium](https://medium.com/@LeapWithAlice)
